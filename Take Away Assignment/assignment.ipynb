{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MCQ Assessment: Python Fundamentals, NumPy, Pandas, and Matplotlib**\n",
    "1. a, b, c\n",
    "2. b\n",
    "3. d\n",
    "4. a\n",
    "5. a, b\n",
    "6. d\n",
    "7. c\n",
    "8. a\n",
    "9. b\n",
    "10. a, c\n",
    "11. b, c\n",
    "12. c\n",
    "13. a, b, c\n",
    "14. a, b, c\n",
    "15. a\n",
    "16. c\n",
    "17. a\n",
    "18. a\n",
    "19. a\n",
    "20. b\n",
    "21. b\n",
    "22. b\n",
    "23. a\n",
    "24. d\n",
    "25. d\n",
    "26. a\n",
    "27. a\n",
    "28. a\n",
    "29. b\n",
    "30. c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"E:\\\\College\\\\LnB\\\\Take Away Assignment\\\\covid19-global-forecasting-week-5\\\\train.csv\", low_memory= False)\n",
    "test_df = pd.read_csv(r\"E:\\\\College\\\\LnB\\\\Take Away Assignment\\\\covid19-global-forecasting-week-5\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Country_Region\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[(train_df[\"County\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"Country_Region\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Country_Region\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = train_df[(train_df['Country_Region'].notna()) & (train_df['Province_State'].notna())].iloc[:,[2,3]]\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df['Country_Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Date'] = pd.to_datetime(train_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country = train_df.groupby(['Country_Region', 'Target'])['TargetValue'].sum().unstack()\n",
    "group_by_country[\"ConfirmedCases\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country[\"Fatalities\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country[\"Recovered\"] = (group_by_country[\"ConfirmedCases\"]) - (group_by_country[\"Fatalities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country[\"Recovered\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['day_of_week'] = train_df['Date'].dt.dayofweek\n",
    "train_df['day_of_month'] = train_df['Date'].dt.day\n",
    "train_df['week_of_year'] = train_df['Date'].dt.isocalendar().week\n",
    "train_df['month'] = train_df['Date'].dt.month\n",
    "train_df['quarter'] = train_df['Date'].dt.quarter\n",
    "train_df['year'] = train_df['Date'].dt.year\n",
    "train_df['is_weekend'] = train_df['Date'].dt.dayofweek >= 5   # is_weekend: Boolean indicating if the day is a weekend (True for Saturday and Sunday)\n",
    "train_df['day_of_year'] = train_df['Date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = train_df[[\"Country_Region\", \"County\", \"Province_State\", \"Population\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf[newdf[\"Country_Region\"].isin(['Australia', 'Canada', 'China', 'Denmark', 'France', 'Netherlands', 'US', 'United Kingdom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population_1 = newdf.groupby([\"Country_Region\"])[\"Population\"].sum().reset_index()\n",
    "grp_population_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population_1[grp_population_1[\"Country_Region\"] == \"Australia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[(train_df[\"Country_Region\"] == \"US\") & (train_df[\"Province_State\"].isna()) & (train_df[\"County\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population_1[grp_population_1[\"Country_Region\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population = newdf.groupby([\"Country_Region\", \"Province_State\"])[\"Population\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population[grp_population[\"Country_Region\"] == \"Austra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population[grp_population[\"Country_Region\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population[grp_population[\"Country_Region\"] == \"US\"][\"Population\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_population[grp_population[\"Country_Region\"] == \"Australia\"][\"Population\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def population(df: pd.DataFrame, result: pd.DataFrame) -> pd.DataFrame:\n",
    "#     for _, row in df.iterrows():\n",
    "#         if pd.isna(row[\"County\"]) and pd.isna(row[\"Province_State\"]):\n",
    "#             if row[\"Country_Region\"] not in result[\"Country_Region\"].values:\n",
    "#                 result.loc[len(result)] = row[\"Country_Region\"]\n",
    "#             if pd.isna(result[\"Population\"]):\n",
    "#                 result.loc[result[\"Country_Region\"] == row[\"Country_Region\"],\"Population\"] = row[\"Country_Region\"]\n",
    "#         else:\n",
    "#             if row[\"Country_Region\"] not in result[\"Country_Region\"].values:\n",
    "#                 result.loc[len(result)] = row[[\"Country_Region\", \"Population\"]]\n",
    "#             if pd.notna(row[\"County\"]) and row[\"County\"] not in result[\"County\"].values:\n",
    "#                 result.loc[len(result)] = row[[\"Country_Region\", \"County\", \"Population\"]]\n",
    "#             if pd.notna(row[\"Province_State\"]) and row[\"Province_State\"] not in result[\"Province_State\"].values:\n",
    "#                 result.loc[len(result)] = row[[\"Country_Region\", \"Province_State\", \"Population\"]]\n",
    "#     return result\n",
    "\n",
    "# a = population(train_df, newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 4s 27ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "8/8 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (252,) (0,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Evaluate model using Mean Squared Error\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmean((\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Squared Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Plot predicted prices\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:110\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:6259\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6258\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 6259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\base.py:1325\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1322\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1325\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:226\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    222\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (252,) (0,) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# !pip install yfinance\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "# Get user input for stock and time period\n",
    "whichstock = input(\"Which stock? > \")\n",
    "howmanyyears = int(input(\"How many years? > \"))\n",
    "\n",
    "# Download historical stock data\n",
    "today = date.today()\n",
    "END_DATE = today.isoformat()\n",
    "START_DATE = date(today.year - howmanyyears, today.month, today.day).isoformat()\n",
    "data = yf.download(whichstock, start=START_DATE, end=END_DATE)\n",
    "\n",
    "# Reset index and convert to datetime\n",
    "data.reset_index(inplace=True)\n",
    "data['Date'] = pd.to_datetime(data.Date)\n",
    "data['Date'] = data['Date'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# Calculate Exponential Moving Averages (EMAs)\n",
    "data['EMA-50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "data['EMA-200'] = data['Close'].ewm(span=200, adjust=False).mean()\n",
    "\n",
    "# Create feature engineering\n",
    "data['Volume_Ratio'] = data['Volume'] / data['Volume'].rolling(window=20).mean()\n",
    "data['Price_Change'] = data['Close'].pct_change()\n",
    "\n",
    "# Scale data using Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "data[['Open', 'High', 'Low', 'Close', 'Volume', 'EMA-50', 'EMA-200', 'Volume_Ratio', 'Price_Change']] = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close', 'Volume', 'EMA-50', 'EMA-200', 'Volume_Ratio', 'Price_Change']])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = data.drop(['Close', 'Date'], axis=1)\n",
    "y = data['Close']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_test = y_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "y_pred[np.isinf(y_pred)] = np.nan\n",
    "y_pred = y_pred[~np.isnan(y_pred)]\n",
    "y_pred = y_pred.reshape(-1,)\n",
    "# Evaluate model using Mean Squared Error\n",
    "mse = np.nanmean((y_test - y_pred) ** 2)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "\n",
    "# Plot predicted prices\n",
    "plt.plot(y_test, label='Actual Prices')\n",
    "plt.plot(y_pred, label='Predicted Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Use model to predict future prices\n",
    "future_prices = []\n",
    "for i in range(3):  # predict prices for the next 3 months\n",
    "    future_date = data.index[-1] + pd.DateOffset(months=i+1)\n",
    "    future_data = pd.DataFrame({'Open': [data['Open'].iloc[-1]], \n",
    "                                'High': [data['High'].iloc[-1]], \n",
    "                                'Low': [data['Low'].iloc[-1]], \n",
    "                                'Close': [data['Close'].iloc[-1]], \n",
    "                                'Volume': [data['Volume'].iloc[-1]], \n",
    "                                'EMA-50': [data['EMA-50'].iloc[-1]], \n",
    "                                'EMA-200': [data['EMA-200'].iloc[-1]], \n",
    "                                'Volume_Ratio': [data['Volume_Ratio'].iloc[-1]], \n",
    "                                'Price_Change': [data['Price_Change'].iloc[-1]]})\n",
    "    future_data = scaler.transform(future_data)\n",
    "    future_price = model.predict(future_data)[0]\n",
    "    future_prices.append((future_date, future_price))\n",
    "\n",
    "# Plot predicted future prices\n",
    "plt.plot([x[0] for x in future_prices], [x[1] for x in future_prices], label='Predicted Future Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
